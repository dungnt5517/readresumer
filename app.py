import streamlit as st
import requests
from bs4 import BeautifulSoup
from ai_providers import gemini
from config import AI_PROVIDER

st.set_page_config(page_title="ğŸ“š ReadResumer", layout="centered")
st.title("ğŸ“š ReadResumer â€“ TÃ³m táº¯t bÃ i viáº¿t trong 5 giÃ¢y")

def extract_text_from_url(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')

    # Láº¥y ná»™i dung tá»« cÃ¡c tháº» <p>
    paragraphs = soup.find_all('p')
    text = "\n".join([p.get_text() for p in paragraphs])
    return text[:5000]  # trÃ¡nh gá»­i quÃ¡ nhiá»u token cho API

url = st.text_input("ğŸ”— Nháº­p URL bÃ i viáº¿t:")

if st.button("TÃ³m táº¯t"):
    if not url:
        st.warning("HÃ£y nháº­p URL há»£p lá»‡.")
    else:
        with st.spinner("ğŸ” Äang táº£i vÃ  xá»­ lÃ½ bÃ i viáº¿t..."):
            try:
                content = extract_text_from_url(url)

                if AI_PROVIDER == "gemini":
                    summary = gemini.summarize_with_gemini(content)
                else:
                    summary = "ChÆ°a há»— trá»£ AI provider nÃ y."

                st.subheader("ğŸ“ TÃ³m táº¯t 3 Ã½ chÃ­nh:")
                for line in summary.split("\n"):
                    if line.strip():
                        st.markdown(f"- {line.strip()}")

            except Exception as e:
                st.error(f"Lá»—i: {e}")
